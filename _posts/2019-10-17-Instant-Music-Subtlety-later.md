---
layout: post
title: "Instant Music, Subtlety later"
date: 2019-10-17 23:45:00 +0200
categories: Interactive-Systems
author: Karolina Jawad
image: \assets\img\Oceans\tableau_vivre_nouveau.jpg
excerpt: "When drafting ideas in unknown territory one can become
overwhelmed with the sheer endless options to create an IMS (interactive music system). Here a real-time processing
board for voice with gesture control."
Keywords: HCI, Performance, Movement, Gestures, Interface, Design, Circuit Bending, Engineering, Art, No-Art, Mapping
---

### “Instant music, subtlety later,”
***(Cook, P. 2001. “Principles for Designing Computer Music Controllers,”)***


### Inspiration
The main principle of my IMS is based on an instrument from 1985, a bit older but not much older than me:
The processing of ambient sound and vocals in real-time through gesture (and granular synthesis) control is something that pioneer Michael Waisvisz [virtuously performed](https://www.youtube.com/watch?v=pYfRORkuPX8) with his 'The Hyperinstrument' / 'The Hands'. It is a fundamental piece in NIME and was among other ideas quite influencing for my way of proceeding. Engineering this form of sonic interaction was adapted by artists like Pamela Z for example. Pamela Z transferred similar principles very interestingly in a complex artistic set-up. Her [performance 'Memory Trace'](https://youtu.be/ntSPtFQdyBA?t=40)  deals with a real-life problem, memory loss. The memory of humans and of engineered circuitry is interesting to make use of performative. It can ideally reflect upon our temporary condition by exploring its artistic dimensions while being embed it in a meaningful context.

However I had to accept that we are operating from another end. And mentioning Michael W and Pamela Z
shows in my perspective this way to approach engineering. There is this state of 'that is possible to create' to
'that is possible to do with'.

### System functions
When drafting ideas in unknown territory one can become overwhelmed with the sheer endless options to create an IMS (interactive music system). There were quite adventurous objects that could produce sounds I went virtually pregnant with. The follow up is usually an ongoing negotiation process between available equipment, own skills, time and research that would determines the final outcome.

* Microphone – capturing sounds of any kind, amplified through vocals
* Potentiometer - Delay, effect
* Slider  - Feedback, effect
* Distance Sensor (Ultra Sound) – granular synthesis, received from input that went through the other effects


<figure>
  <img src="/assets/img/Oceans/k_patch.JPG " width = "100%" align="center" />
  <figcaption>Pure Data Patch with all effects</figcaption>
</figure>

### Mapping and perception
The use of the sound manipulation is not only audible but visible. The mapping of the the Ultra Sound Sensor to gestures is quite linear,
the closer the hand gets to the sensor, the less intense the effect. On a distance of 30 to 50 centimetres the amount of granulation is most dense. In the video below it is perceptible how the hand acts as an synthesizer. The level of engagement and expressivity is certainly limited, but not exhausted after 5 min as there are still unpredictable elements within the interaction.

<figure align="middle">
        <video height="100%" width="100%" controls>
        <source src="https://docs.google.com/uc?export=download&id=1gq6TRjfycnS16U_6garQbvYFzbF3VWTy" type="video/mp4">
        <figcaption><strong>Exploring the instrument. While performing and before.</strong></figcaption>        
        Your browser does not support the video tag.
        </video>
</figure>

In the first part of the video, the performance,  I was trying hard to get control of the processing parameters, compared to the last/first rehearsal which follows after the demo. For some reason it was way more difficult to keep the same amount of control on the single effects as in a relaxed 'unobserved' moment – maybe it was the demo effect as I haven't touched upon the patch any more in the meantime.
The rhythmically performed gestures were helping me to get in tune with the activating the intensity of the granular synthesis and its delay.

The workshop was very fun, however in the development process of the IMS I ended up with and also while exploring the interaction with it I was wondering about how much artistic meaningfulness I could possibly create. Parameters that are important to evaluate the expressivity of an engineered product like
* reliability,
* repeatability
are most likely not sufficient in other context. The unreliable or unpredictable can be a huge part of the aesthetic. Of course, it should not fall apart, on the one hand, the 'success' of a design is its technical realization. On the other hand (again), the level of technical sophistication will never replace meaningful interaction. The context probably determines the evaluation of the outcomes as well. As being someone with a past in theatre, I can hardly extract more than a nice application from it, that counts for all of the instruments. But inspires me to look further and include the potential applicability in the design process. In this interface of creation of things, it feels a little bit like a gap between 'designing' things and creating art. But it can help to generate an intersectional practise of technology, music and theatre for example, which is an inspiration for where one could go beyond the circuitry design.

### Acknowledgements
I would like to thank heartfully all MCT-IMS-Trondheim peers who helped me developing the board, a big thank especially to Sepehr Haghighi! Thanks also to Stefano Fasciani.

### References

* Dobrain, C. The ‘E’ in NIME: Musical Expression with New Computer Interfaces
* Arfib, D. Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces
* Waisvisz, M. The Hands, a set of remote Midi-controllers
* Benjamin, W. The Work of Art in the Age of Mechanical Reproduction
